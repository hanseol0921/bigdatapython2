import requests
from bs4 import BeautifulSoup
import random
import time
import csv

def melon_chart(limit):
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        songs = soup.select('tr[data-song-no]')

        return [(song.select_one('span.rank').text.strip(),
                 song.select_one('div.ellipsis.rank01 a').text.strip(),
                 song.select_one('div.ellipsis.rank02 a').text.strip()) 
                for song in songs[:limit]]
    else:
        print(f"ğŸš¨ ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìƒíƒœ ì½”ë“œ: {response.status_code}")
        return []

def m_random(d):
    print(d)
    time.sleep(1)
    print("[ì¢‹ì•„ìš”! ì œê°€ ì—´ì‹¬íˆ ì°¾ì•„ì„œ ì‚¬ìš©ìë‹˜ê»˜ ë…¸ë˜ë¥¼ í•œ ê³¡ ì¶”ì²œí• ê²Œìš”.]")
    time.sleep(1)
    print(f"[ë‘êµ¬ë‘êµ¬ë‘¥...]")

    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

        songs = soup.select('tr[data-song-no]')
        song_list = []

        for song in songs:
            rank = song.select_one('span.rank').text.strip()
            title = song.select_one('div.ellipsis.rank01 a').text.strip()
            artist = song.select_one('div.ellipsis.rank02 a').text.strip()
            song_list.append((rank, title, artist))

        random_song = random.choice(song_list)
        time.sleep(1)
        print(f"[ì´ ë…¸ë˜ê°€ ì¢‹ì„ ê±° ê°™ì•„ìš”!]")
        time.sleep(1)
        print(f'\n[ì¶”ì²œ ê³¡: {random_song[1]} | ì•„í‹°ìŠ¤íŠ¸: {random_song[2]}]')
    else:
        print(f'[ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. T.T | ìƒíƒœ ì½”ë“œ: {response.status_code}]')


def m100(a):
    print(a)
    time.sleep(1)
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

    songs = soup.select('tr[data-song-no]')

    for index, song in enumerate(songs):
        if index >= 100:
            break
        rank = song.select_one('span.rank').text.strip()
        title = song.select_one('div.ellipsis.rank01 a').text.strip()
        artist = song.select_one('div.ellipsis.rank02 a').text.strip()
        print(f'{rank}ìœ„ {title} - {artist}')

def m50(a):
    print(a)
    time.sleep(1)
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

    songs = soup.select('tr[data-song-no]')

    for index, song in enumerate(songs):
        if index >= 50:
            break
        rank = song.select_one('span.rank').text.strip()
        title = song.select_one('div.ellipsis.rank01 a').text.strip()
        artist = song.select_one('div.ellipsis.rank02 a').text.strip()
        print(f'{rank}ìœ„ {title} - {artist}')


def m10(a):      
    print(a)
    time.sleep(1)
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

    songs = soup.select('tr[data-song-no]')

    for index, song in enumerate(songs):
        if index >= 10:
            break
        rank = song.select_one('span.rank').text.strip()
        title = song.select_one('div.ellipsis.rank01 a').text.strip()
        artist = song.select_one('div.ellipsis.rank02 a').text.strip()
        print(f'{rank}ìœ„ {title} - {artist}')

def m_artist(e):
    print(e)
    time.sleep(1)
    s = input("[ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ê°€ìˆ˜ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.]: ")
    print(f"[<{s}>ì˜ ë…¸ë˜ë¥¼ ê²€ìƒ‰ ì¤‘ì´ì—ìš”...]")
    time.sleep(1)
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        songs = soup.select('tr[data-song-no]')
        found_songs = []

        for song in songs:
            artist = song.select_one('div.ellipsis.rank02 a').text.strip()
            if s.lower() in artist.lower():
                rank = song.select_one('span.rank').text.strip()
                title = song.select_one('div.ellipsis.rank01 a').text.strip()
                found_songs.append((rank, title, artist))

        if found_songs:
            print(f"[<{s}>ì˜ ë…¸ë˜ ëª©ë¡ì´ì—ìš”.]")
            for song in found_songs:
                print(f'{song[0]}ìœ„ {song[1]} - {song[2]}')
        else:
            print(f"[TOP 100ê³¡ ë‚´ <{s}>ì˜ ë…¸ë˜ê°€ ì—†ì–´ìš”.]")
    else:
        print(f'[ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. T.T | ìƒíƒœ ì½”ë“œ: {response.status_code}]')


def melon_csv(f):
    print(f)
    file_path = 'melonTOP100.csv'
    url = 'https://www.melon.com/chart/index.htm'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
        }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

        songs = soup.select('tr[data-song-no]')
        song_list = []

        for song in songs:
            rank = song.select_one('span.rank').text.strip()
            title = song.select_one('div.ellipsis.rank01 a').text.strip()
            artist = song.select_one('div.ellipsis.rank02 a').text.strip()
            song_list.append((rank, title, artist))
    try:
        with open(file_path, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['ìˆœìœ„', 'ì œëª©', 'ì•„í‹°ìŠ¤íŠ¸'])
            writer.writerows(song_list)
            
    except Exception as e:
        print(f"'{file_path}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")